{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP classification code along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any NaN? False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = load_breast_cancer()\n",
    "# raw_data.keys()\n",
    "X, y = raw_data.data, raw_data.target\n",
    "\n",
    "print(f\"Any NaN? {np.isnan(X).any()}\")\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train|Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Hidden1 (Dense)             (None, 32)                992       \n",
      "                                                                 \n",
      " Hidden2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,081\n",
      "Trainable params: 2,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def MLP():\n",
    "    model = Sequential(name = \"MLP\")\n",
    "    model.add(InputLayer(X.shape[1], name = \"Input_layer\"))\n",
    "    model.add(Dense(32, name = \"Hidden1\", activation = \"relu\")) # change to he initializer\n",
    "    model.add(Dense(32, name = \"Hidden2\", activation = \"relu\"))\n",
    "    model.add(Dense(1, name = \"Output\", activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\")\n",
    "    return model\n",
    "\n",
    "model = MLP()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5726 - val_loss: 0.4186\n",
      "Epoch 2/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.3845 - val_loss: 0.3066\n",
      "Epoch 3/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2806 - val_loss: 0.2435\n",
      "Epoch 4/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2147 - val_loss: 0.2030\n",
      "Epoch 5/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1708 - val_loss: 0.1756\n",
      "Epoch 6/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1369 - val_loss: 0.1562\n",
      "Epoch 7/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1160 - val_loss: 0.1427\n",
      "Epoch 8/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1012 - val_loss: 0.1335\n",
      "Epoch 9/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0895 - val_loss: 0.1266\n",
      "Epoch 10/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0807 - val_loss: 0.1206\n",
      "Epoch 11/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0739 - val_loss: 0.1173\n",
      "Epoch 12/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0679 - val_loss: 0.1141\n",
      "Epoch 13/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0629 - val_loss: 0.1116\n",
      "Epoch 14/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.1086\n",
      "Epoch 15/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0557 - val_loss: 0.1062\n",
      "Epoch 16/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.1064\n",
      "Epoch 17/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0490 - val_loss: 0.1055\n",
      "Epoch 18/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0465 - val_loss: 0.1043\n",
      "Epoch 19/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0443 - val_loss: 0.1038\n",
      "Epoch 20/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0422 - val_loss: 0.1018\n",
      "Epoch 21/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.1012\n",
      "Epoch 22/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0387 - val_loss: 0.1014\n",
      "Epoch 23/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0367 - val_loss: 0.1015\n",
      "Epoch 24/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0353 - val_loss: 0.1016\n",
      "Epoch 25/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0333 - val_loss: 0.1021\n",
      "Epoch 26/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0323 - val_loss: 0.1018\n",
      "Epoch 27/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0307 - val_loss: 0.1023\n",
      "Epoch 28/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0299 - val_loss: 0.1029\n",
      "Epoch 29/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0284 - val_loss: 0.1028\n",
      "Epoch 30/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0273 - val_loss: 0.1023\n",
      "Epoch 31/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0259 - val_loss: 0.1043\n",
      "Epoch 32/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0252 - val_loss: 0.1039\n",
      "Epoch 33/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0245 - val_loss: 0.1050\n",
      "Epoch 34/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0231 - val_loss: 0.1057\n",
      "Epoch 35/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0219 - val_loss: 0.1071\n",
      "Epoch 36/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.1051\n",
      "Epoch 37/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0202 - val_loss: 0.1058\n",
      "Epoch 38/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0194 - val_loss: 0.1053\n",
      "Epoch 39/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.1069\n",
      "Epoch 40/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.1076\n",
      "Epoch 41/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.1077\n",
      "Epoch 42/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.1064\n",
      "Epoch 43/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.1070\n",
      "Epoch 44/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.1080\n",
      "Epoch 45/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.1097\n",
      "Epoch 46/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.1078\n",
      "Epoch 47/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.1092\n",
      "Epoch 48/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.1110\n",
      "Epoch 49/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.1130\n",
      "Epoch 50/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.1122\n",
      "Epoch 51/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.1135\n",
      "Epoch 52/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.1150\n",
      "Epoch 53/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.1148\n",
      "Epoch 54/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.1146\n",
      "Epoch 55/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.1164\n",
      "Epoch 56/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.1191\n",
      "Epoch 57/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1187\n",
      "Epoch 58/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.1174\n",
      "Epoch 59/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.1186\n",
      "Epoch 60/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.1190\n",
      "Epoch 61/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.1208\n",
      "Epoch 62/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.1217\n",
      "Epoch 63/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.1215\n",
      "Epoch 64/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.1219\n",
      "Epoch 65/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.1211\n",
      "Epoch 66/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.1242\n",
      "Epoch 67/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.1256\n",
      "Epoch 68/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.1243\n",
      "Epoch 69/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.1267\n",
      "Epoch 70/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.1257\n",
      "Epoch 71/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.1287\n",
      "Epoch 72/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.1286\n",
      "Epoch 73/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.1307\n",
      "Epoch 74/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.1327\n",
      "Epoch 75/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.1390\n",
      "Epoch 76/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.1392\n",
      "Epoch 77/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.1409\n",
      "Epoch 78/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.1424\n",
      "Epoch 79/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.1439\n",
      "Epoch 80/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.1468\n",
      "Epoch 81/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.1460\n",
      "Epoch 82/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.1467\n",
      "Epoch 83/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.1506\n",
      "Epoch 84/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.1539\n",
      "Epoch 85/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.1572\n",
      "Epoch 86/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.1582\n",
      "Epoch 87/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.1592\n",
      "Epoch 88/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.1597\n",
      "Epoch 89/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.1590\n",
      "Epoch 90/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.1592\n",
      "Epoch 91/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.1618\n",
      "Epoch 92/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.1630\n",
      "Epoch 93/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.1647\n",
      "Epoch 94/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.1672\n",
      "Epoch 95/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.1686\n",
      "Epoch 96/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.1690\n",
      "Epoch 97/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.1676\n",
      "Epoch 98/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.1661\n",
      "Epoch 99/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.1675\n",
      "Epoch 100/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.1678\n",
      "Epoch 101/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.1657\n",
      "Epoch 102/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.1666\n",
      "Epoch 103/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.1673\n",
      "Epoch 104/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.1694\n",
      "Epoch 105/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.1700\n",
      "Epoch 106/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.1718\n",
      "Epoch 107/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.1727\n",
      "Epoch 108/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.1750\n",
      "Epoch 109/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.1757\n",
      "Epoch 110/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.1770\n",
      "Epoch 111/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.1776\n",
      "Epoch 112/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.1783\n",
      "Epoch 113/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.1791\n",
      "Epoch 114/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.1807\n",
      "Epoch 115/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.1807\n",
      "Epoch 116/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.1811\n",
      "Epoch 117/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.1821\n",
      "Epoch 118/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.1829\n",
      "Epoch 119/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.1833\n",
      "Epoch 120/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.1840\n",
      "Epoch 121/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.1864\n",
      "Epoch 122/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.1868\n",
      "Epoch 123/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.9871e-04 - val_loss: 0.1873\n",
      "Epoch 124/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.7841e-04 - val_loss: 0.1887\n",
      "Epoch 125/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.5222e-04 - val_loss: 0.1892\n",
      "Epoch 126/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.3184e-04 - val_loss: 0.1888\n",
      "Epoch 127/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.0107e-04 - val_loss: 0.1895\n",
      "Epoch 128/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.9388e-04 - val_loss: 0.1902\n",
      "Epoch 129/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.3834e-04 - val_loss: 0.1913\n",
      "Epoch 130/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.9355e-04 - val_loss: 0.1915\n",
      "Epoch 131/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.1866e-04 - val_loss: 0.1942\n",
      "Epoch 132/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.0985e-04 - val_loss: 0.1959\n",
      "Epoch 133/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.8445e-04 - val_loss: 0.1951\n",
      "Epoch 134/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.6204e-04 - val_loss: 0.1958\n",
      "Epoch 135/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.4779e-04 - val_loss: 0.1961\n",
      "Epoch 136/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.2555e-04 - val_loss: 0.1985\n",
      "Epoch 137/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.0912e-04 - val_loss: 0.2002\n",
      "Epoch 138/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.9456e-04 - val_loss: 0.1969\n",
      "Epoch 139/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.8331e-04 - val_loss: 0.1970\n",
      "Epoch 140/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.6994e-04 - val_loss: 0.1991\n",
      "Epoch 141/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.6057e-04 - val_loss: 0.1976\n",
      "Epoch 142/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.4803e-04 - val_loss: 0.1999\n",
      "Epoch 143/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.5220e-04 - val_loss: 0.2012\n",
      "Epoch 144/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.2091e-04 - val_loss: 0.2020\n",
      "Epoch 145/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.9588e-04 - val_loss: 0.2039\n",
      "Epoch 146/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.8575e-04 - val_loss: 0.2048\n",
      "Epoch 147/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.6638e-04 - val_loss: 0.2064\n",
      "Epoch 148/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.5136e-04 - val_loss: 0.2072\n",
      "Epoch 149/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.4446e-04 - val_loss: 0.2074\n",
      "Epoch 150/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.3314e-04 - val_loss: 0.2082\n",
      "Epoch 151/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.2178e-04 - val_loss: 0.2088\n",
      "Epoch 152/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.2281e-04 - val_loss: 0.2105\n",
      "Epoch 153/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.0559e-04 - val_loss: 0.2114\n",
      "Epoch 154/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.9102e-04 - val_loss: 0.2109\n",
      "Epoch 155/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.0048e-04 - val_loss: 0.2150\n",
      "Epoch 156/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.6454e-04 - val_loss: 0.2149\n",
      "Epoch 157/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.7190e-04 - val_loss: 0.2150\n",
      "Epoch 158/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.5776e-04 - val_loss: 0.2140\n",
      "Epoch 159/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.4942e-04 - val_loss: 0.2145\n",
      "Epoch 160/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.3477e-04 - val_loss: 0.2151\n",
      "Epoch 161/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.3232e-04 - val_loss: 0.2158\n",
      "Epoch 162/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.2587e-04 - val_loss: 0.2173\n",
      "Epoch 163/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.1058e-04 - val_loss: 0.2174\n",
      "Epoch 164/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.0423e-04 - val_loss: 0.2180\n",
      "Epoch 165/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.9974e-04 - val_loss: 0.2188\n",
      "Epoch 166/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.8726e-04 - val_loss: 0.2195\n",
      "Epoch 167/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.8012e-04 - val_loss: 0.2194\n",
      "Epoch 168/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.7451e-04 - val_loss: 0.2205\n",
      "Epoch 169/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.6768e-04 - val_loss: 0.2211\n",
      "Epoch 170/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.6299e-04 - val_loss: 0.2219\n",
      "Epoch 171/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.5823e-04 - val_loss: 0.2231\n",
      "Epoch 172/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.4835e-04 - val_loss: 0.2236\n",
      "Epoch 173/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.4300e-04 - val_loss: 0.2231\n",
      "Epoch 174/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.4329e-04 - val_loss: 0.2239\n",
      "Epoch 175/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.2922e-04 - val_loss: 0.2267\n",
      "Epoch 176/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.2673e-04 - val_loss: 0.2297\n",
      "Epoch 177/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.3045e-04 - val_loss: 0.2298\n",
      "Epoch 178/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.1685e-04 - val_loss: 0.2299\n",
      "Epoch 179/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.0865e-04 - val_loss: 0.2290\n",
      "Epoch 180/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.0375e-04 - val_loss: 0.2300\n",
      "Epoch 181/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.9750e-04 - val_loss: 0.2301\n",
      "Epoch 182/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.9180e-04 - val_loss: 0.2303\n",
      "Epoch 183/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.8727e-04 - val_loss: 0.2319\n",
      "Epoch 184/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.8293e-04 - val_loss: 0.2321\n",
      "Epoch 185/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.7872e-04 - val_loss: 0.2325\n",
      "Epoch 186/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.7426e-04 - val_loss: 0.2331\n",
      "Epoch 187/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.7171e-04 - val_loss: 0.2339\n",
      "Epoch 188/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.6576e-04 - val_loss: 0.2348\n",
      "Epoch 189/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.6131e-04 - val_loss: 0.2349\n",
      "Epoch 190/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.5944e-04 - val_loss: 0.2349\n",
      "Epoch 191/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.5321e-04 - val_loss: 0.2368\n",
      "Epoch 192/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.4941e-04 - val_loss: 0.2356\n",
      "Epoch 193/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.4523e-04 - val_loss: 0.2367\n",
      "Epoch 194/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.4239e-04 - val_loss: 0.2378\n",
      "Epoch 195/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.4219e-04 - val_loss: 0.2387\n",
      "Epoch 196/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.3437e-04 - val_loss: 0.2389\n",
      "Epoch 197/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.3703e-04 - val_loss: 0.2393\n",
      "Epoch 198/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.2681e-04 - val_loss: 0.2400\n",
      "Epoch 199/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.2483e-04 - val_loss: 0.2404\n",
      "Epoch 200/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.2084e-04 - val_loss: 0.2406\n",
      "Epoch 201/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.1525e-04 - val_loss: 0.2413\n",
      "Epoch 202/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.1342e-04 - val_loss: 0.2428\n",
      "Epoch 203/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.1452e-04 - val_loss: 0.2432\n",
      "Epoch 204/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.1351e-04 - val_loss: 0.2435\n",
      "Epoch 205/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.0726e-04 - val_loss: 0.2432\n",
      "Epoch 206/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.0034e-04 - val_loss: 0.2438\n",
      "Epoch 207/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9887e-04 - val_loss: 0.2454\n",
      "Epoch 208/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.9455e-04 - val_loss: 0.2460\n",
      "Epoch 209/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9160e-04 - val_loss: 0.2465\n",
      "Epoch 210/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.8974e-04 - val_loss: 0.2470\n",
      "Epoch 211/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.8586e-04 - val_loss: 0.2471\n",
      "Epoch 212/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.8708e-04 - val_loss: 0.2475\n",
      "Epoch 213/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.8125e-04 - val_loss: 0.2480\n",
      "Epoch 214/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.7985e-04 - val_loss: 0.2493\n",
      "Epoch 215/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.7652e-04 - val_loss: 0.2499\n",
      "Epoch 216/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.7356e-04 - val_loss: 0.2499\n",
      "Epoch 217/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.7216e-04 - val_loss: 0.2504\n",
      "Epoch 218/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.6954e-04 - val_loss: 0.2517\n",
      "Epoch 219/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.6624e-04 - val_loss: 0.2518\n",
      "Epoch 220/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.6335e-04 - val_loss: 0.2504\n",
      "Epoch 221/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.6173e-04 - val_loss: 0.2508\n",
      "Epoch 222/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.6511e-04 - val_loss: 0.2510\n",
      "Epoch 223/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.5619e-04 - val_loss: 0.2536\n",
      "Epoch 224/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.5644e-04 - val_loss: 0.2550\n",
      "Epoch 225/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.5268e-04 - val_loss: 0.2535\n",
      "Epoch 226/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.5008e-04 - val_loss: 0.2540\n",
      "Epoch 227/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.4957e-04 - val_loss: 0.2544\n",
      "Epoch 228/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.4664e-04 - val_loss: 0.2555\n",
      "Epoch 229/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.4426e-04 - val_loss: 0.2567\n",
      "Epoch 230/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.4313e-04 - val_loss: 0.2574\n",
      "Epoch 231/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.4133e-04 - val_loss: 0.2574\n",
      "Epoch 232/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.3778e-04 - val_loss: 0.2586\n",
      "Epoch 233/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.3575e-04 - val_loss: 0.2589\n",
      "Epoch 234/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.3565e-04 - val_loss: 0.2597\n",
      "Epoch 235/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.3257e-04 - val_loss: 0.2594\n",
      "Epoch 236/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.3128e-04 - val_loss: 0.2606\n",
      "Epoch 237/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.2907e-04 - val_loss: 0.2609\n",
      "Epoch 238/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.2738e-04 - val_loss: 0.2608\n",
      "Epoch 239/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.2660e-04 - val_loss: 0.2620\n",
      "Epoch 240/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.2586e-04 - val_loss: 0.2620\n",
      "Epoch 241/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.2294e-04 - val_loss: 0.2628\n",
      "Epoch 242/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2076e-04 - val_loss: 0.2631\n",
      "Epoch 243/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.2000e-04 - val_loss: 0.2637\n",
      "Epoch 244/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.1842e-04 - val_loss: 0.2648\n",
      "Epoch 245/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.1633e-04 - val_loss: 0.2660\n",
      "Epoch 246/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.1495e-04 - val_loss: 0.2666\n",
      "Epoch 247/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.1352e-04 - val_loss: 0.2672\n",
      "Epoch 248/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.1293e-04 - val_loss: 0.2672\n",
      "Epoch 249/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.0925e-04 - val_loss: 0.2673\n",
      "Epoch 250/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.1009e-04 - val_loss: 0.2680\n",
      "Epoch 251/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.0841e-04 - val_loss: 0.2680\n",
      "Epoch 252/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.0703e-04 - val_loss: 0.2689\n",
      "Epoch 253/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.0680e-04 - val_loss: 0.2709\n",
      "Epoch 254/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.0421e-04 - val_loss: 0.2711\n",
      "Epoch 255/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.0346e-04 - val_loss: 0.2711\n",
      "Epoch 256/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.0086e-04 - val_loss: 0.2714\n",
      "Epoch 257/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.0007e-04 - val_loss: 0.2713\n",
      "Epoch 258/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.8765e-05 - val_loss: 0.2731\n",
      "Epoch 259/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.7310e-05 - val_loss: 0.2740\n",
      "Epoch 260/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.6229e-05 - val_loss: 0.2742\n",
      "Epoch 261/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.5101e-05 - val_loss: 0.2739\n",
      "Epoch 262/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.4170e-05 - val_loss: 0.2748\n",
      "Epoch 263/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.3396e-05 - val_loss: 0.2764\n",
      "Epoch 264/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.1409e-05 - val_loss: 0.2766\n",
      "Epoch 265/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.0634e-05 - val_loss: 0.2770\n",
      "Epoch 266/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.9452e-05 - val_loss: 0.2782\n",
      "Epoch 267/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.8007e-05 - val_loss: 0.2783\n",
      "Epoch 268/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.7939e-05 - val_loss: 0.2786\n",
      "Epoch 269/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.5463e-05 - val_loss: 0.2796\n",
      "Epoch 270/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.5061e-05 - val_loss: 0.2801\n",
      "Epoch 271/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.4063e-05 - val_loss: 0.2800\n",
      "Epoch 272/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.3161e-05 - val_loss: 0.2805\n",
      "Epoch 273/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.1656e-05 - val_loss: 0.2818\n",
      "Epoch 274/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.0631e-05 - val_loss: 0.2820\n",
      "Epoch 275/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.0405e-05 - val_loss: 0.2827\n",
      "Epoch 276/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.9747e-05 - val_loss: 0.2833\n",
      "Epoch 277/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.8473e-05 - val_loss: 0.2845\n",
      "Epoch 278/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.7178e-05 - val_loss: 0.2849\n",
      "Epoch 279/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.5864e-05 - val_loss: 0.2853\n",
      "Epoch 280/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.4991e-05 - val_loss: 0.2851\n",
      "Epoch 281/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.3929e-05 - val_loss: 0.2850\n",
      "Epoch 282/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.3089e-05 - val_loss: 0.2853\n",
      "Epoch 283/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.2393e-05 - val_loss: 0.2858\n",
      "Epoch 284/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.1229e-05 - val_loss: 0.2866\n",
      "Epoch 285/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.1120e-05 - val_loss: 0.2875\n",
      "Epoch 286/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.9559e-05 - val_loss: 0.2886\n",
      "Epoch 287/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.9494e-05 - val_loss: 0.2892\n",
      "Epoch 288/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.7973e-05 - val_loss: 0.2888\n",
      "Epoch 289/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.7082e-05 - val_loss: 0.2894\n",
      "Epoch 290/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.6402e-05 - val_loss: 0.2901\n",
      "Epoch 291/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.5984e-05 - val_loss: 0.2906\n",
      "Epoch 292/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.4574e-05 - val_loss: 0.2913\n",
      "Epoch 293/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.4650e-05 - val_loss: 0.2917\n",
      "Epoch 294/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.2988e-05 - val_loss: 0.2922\n",
      "Epoch 295/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.2373e-05 - val_loss: 0.2924\n",
      "Epoch 296/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.2042e-05 - val_loss: 0.2936\n",
      "Epoch 297/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.0810e-05 - val_loss: 0.2938\n",
      "Epoch 298/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.1695e-05 - val_loss: 0.2936\n",
      "Epoch 299/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.1000e-05 - val_loss: 0.2957\n",
      "Epoch 300/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.0625e-05 - val_loss: 0.2961\n",
      "Epoch 301/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.8614e-05 - val_loss: 0.2962\n",
      "Epoch 302/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.7748e-05 - val_loss: 0.2968\n",
      "Epoch 303/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.6768e-05 - val_loss: 0.2988\n",
      "Epoch 304/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.6416e-05 - val_loss: 0.2991\n",
      "Epoch 305/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.5231e-05 - val_loss: 0.2992\n",
      "Epoch 306/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.4691e-05 - val_loss: 0.2995\n",
      "Epoch 307/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.4275e-05 - val_loss: 0.3000\n",
      "Epoch 308/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.4083e-05 - val_loss: 0.3002\n",
      "Epoch 309/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.3130e-05 - val_loss: 0.3022\n",
      "Epoch 310/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.3321e-05 - val_loss: 0.3023\n",
      "Epoch 311/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.2022e-05 - val_loss: 0.3024\n",
      "Epoch 312/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.0752e-05 - val_loss: 0.3021\n",
      "Epoch 313/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.0066e-05 - val_loss: 0.3027\n",
      "Epoch 314/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.9401e-05 - val_loss: 0.3026\n",
      "Epoch 315/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.8856e-05 - val_loss: 0.3030\n",
      "Epoch 316/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.8933e-05 - val_loss: 0.3039\n",
      "Epoch 317/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.8018e-05 - val_loss: 0.3043\n",
      "Epoch 318/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.7075e-05 - val_loss: 0.3048\n",
      "Epoch 319/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.6864e-05 - val_loss: 0.3049\n",
      "Epoch 320/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.6582e-05 - val_loss: 0.3053\n",
      "Epoch 321/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.5845e-05 - val_loss: 0.3057\n",
      "Epoch 322/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.5491e-05 - val_loss: 0.3062\n",
      "Epoch 323/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.5153e-05 - val_loss: 0.3068\n",
      "Epoch 324/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.4243e-05 - val_loss: 0.3064\n",
      "Epoch 325/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.3867e-05 - val_loss: 0.3071\n",
      "Epoch 326/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.3552e-05 - val_loss: 0.3088\n",
      "Epoch 327/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.3160e-05 - val_loss: 0.3093\n",
      "Epoch 328/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.2332e-05 - val_loss: 0.3098\n",
      "Epoch 329/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.1855e-05 - val_loss: 0.3103\n",
      "Epoch 330/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.1491e-05 - val_loss: 0.3103\n",
      "Epoch 331/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.0810e-05 - val_loss: 0.3102\n",
      "Epoch 332/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.0938e-05 - val_loss: 0.3106\n",
      "Epoch 333/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.0817e-05 - val_loss: 0.3111\n",
      "Epoch 334/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.1586e-05 - val_loss: 0.3125\n",
      "Epoch 335/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.0647e-05 - val_loss: 0.3126\n",
      "Epoch 336/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.9591e-05 - val_loss: 0.3126\n",
      "Epoch 337/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.8861e-05 - val_loss: 0.3122\n",
      "Epoch 338/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.8210e-05 - val_loss: 0.3131\n",
      "Epoch 339/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.7999e-05 - val_loss: 0.3138\n",
      "Epoch 340/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.7484e-05 - val_loss: 0.3149\n",
      "Epoch 341/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.6917e-05 - val_loss: 0.3155\n",
      "Epoch 342/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.6399e-05 - val_loss: 0.3159\n",
      "Epoch 343/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.6165e-05 - val_loss: 0.3164\n",
      "Epoch 344/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.5824e-05 - val_loss: 0.3170\n",
      "Epoch 345/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.5320e-05 - val_loss: 0.3170\n",
      "Epoch 346/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.4989e-05 - val_loss: 0.3176\n",
      "Epoch 347/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.4682e-05 - val_loss: 0.3186\n",
      "Epoch 348/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.4299e-05 - val_loss: 0.3186\n",
      "Epoch 349/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.4110e-05 - val_loss: 0.3188\n",
      "Epoch 350/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.3635e-05 - val_loss: 0.3196\n",
      "Epoch 351/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.3284e-05 - val_loss: 0.3204\n",
      "Epoch 352/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.3242e-05 - val_loss: 0.3212\n",
      "Epoch 353/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.2717e-05 - val_loss: 0.3211\n",
      "Epoch 354/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.2464e-05 - val_loss: 0.3215\n",
      "Epoch 355/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.2141e-05 - val_loss: 0.3215\n",
      "Epoch 356/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.1673e-05 - val_loss: 0.3220\n",
      "Epoch 357/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.1547e-05 - val_loss: 0.3229\n",
      "Epoch 358/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.1164e-05 - val_loss: 0.3229\n",
      "Epoch 359/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.0916e-05 - val_loss: 0.3237\n",
      "Epoch 360/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.0577e-05 - val_loss: 0.3245\n",
      "Epoch 361/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.0548e-05 - val_loss: 0.3246\n",
      "Epoch 362/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.9955e-05 - val_loss: 0.3252\n",
      "Epoch 363/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.9785e-05 - val_loss: 0.3253\n",
      "Epoch 364/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.9419e-05 - val_loss: 0.3260\n",
      "Epoch 365/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.9231e-05 - val_loss: 0.3265\n",
      "Epoch 366/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.9041e-05 - val_loss: 0.3268\n",
      "Epoch 367/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.8608e-05 - val_loss: 0.3269\n",
      "Epoch 368/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.8518e-05 - val_loss: 0.3275\n",
      "Epoch 369/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.8101e-05 - val_loss: 0.3282\n",
      "Epoch 370/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.7859e-05 - val_loss: 0.3282\n",
      "Epoch 371/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.7617e-05 - val_loss: 0.3289\n",
      "Epoch 372/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.7444e-05 - val_loss: 0.3288\n",
      "Epoch 373/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.7076e-05 - val_loss: 0.3290\n",
      "Epoch 374/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.6799e-05 - val_loss: 0.3296\n",
      "Epoch 375/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.6580e-05 - val_loss: 0.3299\n",
      "Epoch 376/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.6347e-05 - val_loss: 0.3305\n",
      "Epoch 377/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.6109e-05 - val_loss: 0.3312\n",
      "Epoch 378/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6089e-05 - val_loss: 0.3308\n",
      "Epoch 379/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.5786e-05 - val_loss: 0.3312\n",
      "Epoch 380/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.5366e-05 - val_loss: 0.3317\n",
      "Epoch 381/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.5152e-05 - val_loss: 0.3322\n",
      "Epoch 382/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.4955e-05 - val_loss: 0.3325\n",
      "Epoch 383/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.4837e-05 - val_loss: 0.3327\n",
      "Epoch 384/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.4526e-05 - val_loss: 0.3336\n",
      "Epoch 385/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.4355e-05 - val_loss: 0.3333\n",
      "Epoch 386/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.4134e-05 - val_loss: 0.3339\n",
      "Epoch 387/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.3847e-05 - val_loss: 0.3346\n",
      "Epoch 388/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.3684e-05 - val_loss: 0.3349\n",
      "Epoch 389/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.3463e-05 - val_loss: 0.3353\n",
      "Epoch 390/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.3218e-05 - val_loss: 0.3362\n",
      "Epoch 391/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.3088e-05 - val_loss: 0.3363\n",
      "Epoch 392/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.2949e-05 - val_loss: 0.3363\n",
      "Epoch 393/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.2675e-05 - val_loss: 0.3368\n",
      "Epoch 394/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.2406e-05 - val_loss: 0.3371\n",
      "Epoch 395/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.2335e-05 - val_loss: 0.3375\n",
      "Epoch 396/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.2115e-05 - val_loss: 0.3378\n",
      "Epoch 397/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.1862e-05 - val_loss: 0.3381\n",
      "Epoch 398/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.1911e-05 - val_loss: 0.3388\n",
      "Epoch 399/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.1578e-05 - val_loss: 0.3393\n",
      "Epoch 400/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.1353e-05 - val_loss: 0.3395\n",
      "Epoch 401/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.1145e-05 - val_loss: 0.3394\n",
      "Epoch 402/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.0940e-05 - val_loss: 0.3396\n",
      "Epoch 403/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.0807e-05 - val_loss: 0.3400\n",
      "Epoch 404/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.0587e-05 - val_loss: 0.3403\n",
      "Epoch 405/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.0424e-05 - val_loss: 0.3404\n",
      "Epoch 406/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.0157e-05 - val_loss: 0.3402\n",
      "Epoch 407/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 2.0050e-05 - val_loss: 0.3403\n",
      "Epoch 408/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.9845e-05 - val_loss: 0.3414\n",
      "Epoch 409/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.9700e-05 - val_loss: 0.3417\n",
      "Epoch 410/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.9610e-05 - val_loss: 0.3423\n",
      "Epoch 411/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.9563e-05 - val_loss: 0.3428\n",
      "Epoch 412/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9177e-05 - val_loss: 0.3428\n",
      "Epoch 413/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.9092e-05 - val_loss: 0.3434\n",
      "Epoch 414/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.9008e-05 - val_loss: 0.3437\n",
      "Epoch 415/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.8732e-05 - val_loss: 0.3442\n",
      "Epoch 416/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.8458e-05 - val_loss: 0.3443\n",
      "Epoch 417/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.8391e-05 - val_loss: 0.3445\n",
      "Epoch 418/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.8221e-05 - val_loss: 0.3450\n",
      "Epoch 419/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.8123e-05 - val_loss: 0.3460\n",
      "Epoch 420/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.7931e-05 - val_loss: 0.3458\n",
      "Epoch 421/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.7784e-05 - val_loss: 0.3461\n",
      "Epoch 422/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.7692e-05 - val_loss: 0.3461\n",
      "Epoch 423/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.7367e-05 - val_loss: 0.3467\n",
      "Epoch 424/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.7295e-05 - val_loss: 0.3475\n",
      "Epoch 425/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.7091e-05 - val_loss: 0.3481\n",
      "Epoch 426/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.7047e-05 - val_loss: 0.3486\n",
      "Epoch 427/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.6826e-05 - val_loss: 0.3494\n",
      "Epoch 428/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.6708e-05 - val_loss: 0.3494\n",
      "Epoch 429/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.6498e-05 - val_loss: 0.3500\n",
      "Epoch 430/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.6377e-05 - val_loss: 0.3502\n",
      "Epoch 431/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.6269e-05 - val_loss: 0.3505\n",
      "Epoch 432/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.5968e-05 - val_loss: 0.3506\n",
      "Epoch 433/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.6123e-05 - val_loss: 0.3510\n",
      "Epoch 434/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.6081e-05 - val_loss: 0.3516\n",
      "Epoch 435/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.5713e-05 - val_loss: 0.3515\n",
      "Epoch 436/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.5529e-05 - val_loss: 0.3518\n",
      "Epoch 437/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.5448e-05 - val_loss: 0.3532\n",
      "Epoch 438/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.5261e-05 - val_loss: 0.3536\n",
      "Epoch 439/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.5200e-05 - val_loss: 0.3534\n",
      "Epoch 440/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.5070e-05 - val_loss: 0.3537\n",
      "Epoch 441/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.5040e-05 - val_loss: 0.3543\n",
      "Epoch 442/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.4859e-05 - val_loss: 0.3546\n",
      "Epoch 443/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.4616e-05 - val_loss: 0.3548\n",
      "Epoch 444/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.4513e-05 - val_loss: 0.3552\n",
      "Epoch 445/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.4451e-05 - val_loss: 0.3554\n",
      "Epoch 446/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.4260e-05 - val_loss: 0.3557\n",
      "Epoch 447/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.4170e-05 - val_loss: 0.3560\n",
      "Epoch 448/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.4049e-05 - val_loss: 0.3562\n",
      "Epoch 449/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.3973e-05 - val_loss: 0.3564\n",
      "Epoch 450/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.3866e-05 - val_loss: 0.3567\n",
      "Epoch 451/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.3836e-05 - val_loss: 0.3579\n",
      "Epoch 452/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.3696e-05 - val_loss: 0.3586\n",
      "Epoch 453/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.3497e-05 - val_loss: 0.3590\n",
      "Epoch 454/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.3394e-05 - val_loss: 0.3594\n",
      "Epoch 455/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.3261e-05 - val_loss: 0.3598\n",
      "Epoch 456/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.3149e-05 - val_loss: 0.3599\n",
      "Epoch 457/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.3150e-05 - val_loss: 0.3603\n",
      "Epoch 458/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.2962e-05 - val_loss: 0.3613\n",
      "Epoch 459/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.2861e-05 - val_loss: 0.3611\n",
      "Epoch 460/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.2723e-05 - val_loss: 0.3613\n",
      "Epoch 461/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.2682e-05 - val_loss: 0.3618\n",
      "Epoch 462/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.2558e-05 - val_loss: 0.3621\n",
      "Epoch 463/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.2459e-05 - val_loss: 0.3625\n",
      "Epoch 464/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.2369e-05 - val_loss: 0.3629\n",
      "Epoch 465/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.2299e-05 - val_loss: 0.3629\n",
      "Epoch 466/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.2152e-05 - val_loss: 0.3632\n",
      "Epoch 467/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.2065e-05 - val_loss: 0.3639\n",
      "Epoch 468/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.1950e-05 - val_loss: 0.3650\n",
      "Epoch 469/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.1881e-05 - val_loss: 0.3650\n",
      "Epoch 470/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.1836e-05 - val_loss: 0.3652\n",
      "Epoch 471/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.1726e-05 - val_loss: 0.3656\n",
      "Epoch 472/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.1574e-05 - val_loss: 0.3659\n",
      "Epoch 473/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.1614e-05 - val_loss: 0.3660\n",
      "Epoch 474/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.1388e-05 - val_loss: 0.3668\n",
      "Epoch 475/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.1277e-05 - val_loss: 0.3668\n",
      "Epoch 476/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.1212e-05 - val_loss: 0.3670\n",
      "Epoch 477/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.1070e-05 - val_loss: 0.3676\n",
      "Epoch 478/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.0993e-05 - val_loss: 0.3680\n",
      "Epoch 479/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.0932e-05 - val_loss: 0.3683\n",
      "Epoch 480/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.0907e-05 - val_loss: 0.3693\n",
      "Epoch 481/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.0792e-05 - val_loss: 0.3695\n",
      "Epoch 482/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.0668e-05 - val_loss: 0.3684\n",
      "Epoch 483/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.0574e-05 - val_loss: 0.3688\n",
      "Epoch 484/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.0520e-05 - val_loss: 0.3695\n",
      "Epoch 485/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.0384e-05 - val_loss: 0.3696\n",
      "Epoch 486/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.0453e-05 - val_loss: 0.3706\n",
      "Epoch 487/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.0183e-05 - val_loss: 0.3708\n",
      "Epoch 488/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.0107e-05 - val_loss: 0.3711\n",
      "Epoch 489/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.0000e-05 - val_loss: 0.3716\n",
      "Epoch 490/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.9357e-06 - val_loss: 0.3720\n",
      "Epoch 491/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.8960e-06 - val_loss: 0.3724\n",
      "Epoch 492/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.7756e-06 - val_loss: 0.3728\n",
      "Epoch 493/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.6853e-06 - val_loss: 0.3728\n",
      "Epoch 494/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.6231e-06 - val_loss: 0.3732\n",
      "Epoch 495/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.5465e-06 - val_loss: 0.3734\n",
      "Epoch 496/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.4771e-06 - val_loss: 0.3739\n",
      "Epoch 497/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.4126e-06 - val_loss: 0.3743\n",
      "Epoch 498/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.3554e-06 - val_loss: 0.3750\n",
      "Epoch 499/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.2411e-06 - val_loss: 0.3753\n",
      "Epoch 500/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.1577e-06 - val_loss: 0.3752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x151406da0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X_train, y_train, epochs = 500, validation_split = .2, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_loss = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.572582</td>\n",
       "      <td>0.418566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.384536</td>\n",
       "      <td>0.306566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.280639</td>\n",
       "      <td>0.243542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.214663</td>\n",
       "      <td>0.203023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.170770</td>\n",
       "      <td>0.175566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  val_loss\n",
       "0  0.572582  0.418566\n",
       "1  0.384536  0.306566\n",
       "2  0.280639  0.243542\n",
       "3  0.214663  0.203023\n",
       "4  0.170770  0.175566"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_loss.plot()\n",
    "# clear overfitting as vvalidation loss increases after a certain amount of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Hidden1 (Dense)             (None, 32)                992       \n",
      "                                                                 \n",
      " Hidden2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,081\n",
      "Trainable params: 2,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MLP()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5243 - val_loss: 0.4194\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.3608 - val_loss: 0.3222\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2637 - val_loss: 0.2629\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2013 - val_loss: 0.2234\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1607 - val_loss: 0.1940\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1341 - val_loss: 0.1769\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1155 - val_loss: 0.1648\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1013 - val_loss: 0.1558\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0910 - val_loss: 0.1493\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0825 - val_loss: 0.1437\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0752 - val_loss: 0.1406\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0703 - val_loss: 0.1371\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0648 - val_loss: 0.1350\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.1329\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0567 - val_loss: 0.1314\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.1300\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0508 - val_loss: 0.1283\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0479 - val_loss: 0.1282\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0457 - val_loss: 0.1279\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0438 - val_loss: 0.1282\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.1290\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0394 - val_loss: 0.1289\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0377 - val_loss: 0.1302\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.1300\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0347 - val_loss: 0.1311\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0330 - val_loss: 0.1316\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0315 - val_loss: 0.1331\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0303 - val_loss: 0.1339\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0293 - val_loss: 0.1335\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0282 - val_loss: 0.1333\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0267 - val_loss: 0.1340\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0252 - val_loss: 0.1334\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.1346\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0230 - val_loss: 0.1353\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0217 - val_loss: 0.1344\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0207 - val_loss: 0.1331\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0199 - val_loss: 0.1346\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.1330\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.1345\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.1350\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.1365\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.1360\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.1355\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.1336\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.1341\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.1352\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.1350\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.1351\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.1356\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.1359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1517d7b20>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X_train, y_train, epochs = 50, validation_split = .2, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(model.history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15226c2e0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP()\n",
    "model.fit(scaled_X_train, y_train, epochs = 50, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        43\n",
      "           1       0.99      0.99      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.98      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_pred = model.predict(scaled_X_test)\n",
    "#np.round(y_pred)\n",
    "y_pred = (y_pred > 0.5) * 1 # threshold\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(cm).plot()\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15a17b4873019ca273a3ebd27410a531cffac751f84497b09afeba222ba2b43d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('deeplearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
